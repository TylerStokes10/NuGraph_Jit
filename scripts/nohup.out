GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
data path = /home/stokes/hA_LFG_Atm_h5/Atm_Semantic/out_processed.evt.h5.0000.h5
using checkpoint = /home/stokes/NEW_WORK/GNN_Work/NuGraph_Multi_Training/hA_LFGV24/version_0/checkpoints/epoch=79-step=80800.ckpt
output file = /home/stokes/NEW_WORK/GNN_Work/NuGraph_Multi_Training/Event_Semantic/
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/26 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/stokes/NuGraph_v24_4/scripts/test.py", line 57, in <module>
    test(args)
  File "/home/stokes/NuGraph_v24_4/scripts/test.py", line 42, in test
    out = trainer.predict(model, dataloaders=nudata.test_dataloader())
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 864, in predict
    return call._call_and_handle_interrupt(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 903, in _predict_impl
    results = self._run(model, ckpt_path=ckpt_path)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1028, in _run_stage
    return self.predict_loop.run()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/loops/prediction_loop.py", line 124, in run
    self._predict_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/loops/prediction_loop.py", line 253, in _predict_step
    predictions = call._call_strategy_hook(trainer, "predict_step", *step_args)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 438, in predict_step
    return self.lightning_module.predict_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/NuGraph/nugraph/models/nugraph3/NuGraph3.py", line 228, in predict_step
    self.step(batch)
  File "/home/stokes/NuGraph/nugraph/models/nugraph3/NuGraph3.py", line 134, in step
    x = self(batch.collect('x'),
        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/NuGraph/nugraph/models/nugraph3/NuGraph3.py", line 111, in forward
    m = self.encoder(x)
        ^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/NuGraph/nugraph/models/nugraph3/encoder.py", line 19, in forward
    return { p: net(x[p]) for p, net in self.net.items() }
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/NuGraph/nugraph/models/nugraph3/encoder.py", line 19, in <dictcomp>
    return { p: net(x[p]) for p, net in self.net.items() }
                ^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacty of 10.91 GiB of which 13.12 MiB is free. Process 33328 has 10.70 GiB memory in use. Including non-PyTorch memory, this process has 180.00 MiB memory in use. Of the allocated memory 18.10 MiB is allocated by PyTorch, and 9.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Predicting DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/stokes/NuGraph_v24_4/scripts/test.py", line 5, in <module>
    import pandas as pd
ModuleNotFoundError: No module named 'pandas'
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
data path = /home/stokes/hA_LFG_Atm_h5/Atm_Semantic/out_processed.evt.h5.0000.h5
using checkpoint = /home/stokes/NEW_WORK/GNN_Work/NuGraph_Multi_Training/hA_LFGV24/version_0/checkpoints/epoch=79-step=80800.ckpt
output file = /home/stokes/NEW_WORK/GNN_Work/NuGraph_Multi_Training/Event_Semantic/
Predicting: |          | 0/? [00:00<?, ?it/s]Predicting:   0%|          | 0/26 [00:00<?, ?it/s]Predicting DataLoader 0:   0%|          | 0/26 [00:00<?, ?it/s]/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'y'}'. Please explicitly set 'num_nodes' as an attribute of 'data[evt]' to suppress this warning
  warnings.warn(
Predicting DataLoader 0:   4%|▍         | 1/26 [00:01<00:36,  0.68it/s]Predicting DataLoader 0:   8%|▊         | 2/26 [00:04<00:53,  0.45it/s]Predicting DataLoader 0:  12%|█▏        | 3/26 [00:07<00:57,  0.40it/s]Predicting DataLoader 0:  15%|█▌        | 4/26 [00:11<01:04,  0.34it/s]Predicting DataLoader 0:  19%|█▉        | 5/26 [00:15<01:05,  0.32it/s]Predicting DataLoader 0:  23%|██▎       | 6/26 [00:18<01:02,  0.32it/s]Predicting DataLoader 0:  27%|██▋       | 7/26 [00:21<00:58,  0.33it/s]Predicting DataLoader 0:  31%|███       | 8/26 [00:24<00:54,  0.33it/s]Predicting DataLoader 0:  35%|███▍      | 9/26 [00:26<00:50,  0.34it/s]Predicting DataLoader 0:  38%|███▊      | 10/26 [00:29<00:47,  0.34it/s]Predicting DataLoader 0:  42%|████▏     | 11/26 [00:32<00:44,  0.34it/s]Predicting DataLoader 0:  46%|████▌     | 12/26 [00:35<00:40,  0.34it/s]Predicting DataLoader 0:  50%|█████     | 13/26 [00:37<00:37,  0.34it/s]Predicting DataLoader 0:  54%|█████▍    | 14/26 [00:40<00:34,  0.35it/s]Predicting DataLoader 0:  58%|█████▊    | 15/26 [00:42<00:31,  0.35it/s]Predicting DataLoader 0:  62%|██████▏   | 16/26 [00:45<00:28,  0.35it/s]Predicting DataLoader 0:  65%|██████▌   | 17/26 [00:48<00:25,  0.35it/s]Predicting DataLoader 0:  69%|██████▉   | 18/26 [00:50<00:22,  0.35it/s]Predicting DataLoader 0:  73%|███████▎  | 19/26 [00:53<00:19,  0.35it/s]Predicting DataLoader 0:  77%|███████▋  | 20/26 [00:55<00:16,  0.36it/s]Predicting DataLoader 0:  81%|████████  | 21/26 [00:58<00:13,  0.36it/s]Predicting DataLoader 0:  85%|████████▍ | 22/26 [01:00<00:11,  0.36it/s]Predicting DataLoader 0:  88%|████████▊ | 23/26 [01:03<00:08,  0.36it/s]Predicting DataLoader 0:  92%|█████████▏| 24/26 [01:05<00:05,  0.37it/s]Predicting DataLoader 0:  96%|█████████▌| 25/26 [01:07<00:02,  0.37it/s]Predicting DataLoader 0: 100%|██████████| 26/26 [01:08<00:00,  0.38it/s]Predicting DataLoader 0: 100%|██████████| 26/26 [01:08<00:00,  0.38it/s]
inference for 1617 events is 68.82531809806824 s (that's 0.04256358571309105 s/graph
  0%|          | 0/26 [00:00<?, ?it/s]  0%|          | 0/26 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/stokes/NuGraph_v24_4/scripts/test.py", line 57, in <module>
    test(args)
  File "/home/stokes/NuGraph_v24_4/scripts/test.py", line 50, in test
    for data in batch.to_data_list():
                ^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/data/batch.py", line 193, in to_data_list
    return [self.get_example(i) for i in range(self.num_graphs)]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/data/batch.py", line 193, in <listcomp>
    return [self.get_example(i) for i in range(self.num_graphs)]
            ^^^^^^^^^^^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/data/batch.py", line 124, in get_example
    data = separate(
           ^^^^^^^^^
  File "/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/data/separate.py", line 35, in separate
    attrs = slice_dict[key].keys()
            ~~~~~~~~~~^^^^^
KeyError: 'sp'
/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'v', 'y', 'u'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.
  warnings.warn(
/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'sp'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.
  warnings.warn(
/home/stokes/mambaforge/envs/numl/lib/python3.11/site-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'evt'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.
  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loading `train_dataloader` to estimate number of stepping batches.

  | Name             | Type             | Params
------------------------------------------------------
0 | encoder          | HeteroDictLinear | 3.5 K 
1 | core_net         | NuGraphCore      | 481 K 
2 | event_decoder    | EventDecoder     | 67    
3 | semantic_decoder | SemanticDecoder  | 2.7 K 
------------------------------------------------------
487 K     Trainable params
0         Non-trainable params
487 K     Total params
1.949     Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:05<00:05,  0.20it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:08<00:00,  0.23it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/7584 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/7584 [00:00<?, ?it/s] Epoch 0:   0%|          | 1/7584 [00:06<12:51:48,  0.16it/s]Epoch 0:   0%|          | 1/7584 [00:06<12:51:51,  0.16it/s, v_num=0, loss/train=4.590]Epoch 0:   0%|          | 2/7584 [00:17<18:34:40,  0.11it/s, v_num=0, loss/train=4.590]Epoch 0:   0%|          | 2/7584 [00:17<18:43:11,  0.11it/s, v_num=0, loss/train=4.540]Epoch 0:   0%|          | 3/7584 [00:22<15:55:23,  0.13it/s, v_num=0, loss/train=4.540]Epoch 0:   0%|          | 3/7584 [00:22<16:00:40,  0.13it/s, v_num=0, loss/train=4.420]Epoch 0:   0%|          | 4/7584 [00:26<13:52:23,  0.15it/s, v_num=0, loss/train=4.420]Epoch 0:   0%|          | 4/7584 [00:26<13:56:57,  0.15it/s, v_num=0, loss/train=4.660]Epoch 0:   0%|          | 5/7584 [00:30<12:41:32,  0.17it/s, v_num=0, loss/train=4.660]Epoch 0:   0%|          | 5/7584 [00:30<12:44:57,  0.17it/s, v_num=0, loss/train=4.510]Epoch 0:   0%|          | 6/7584 [00:34<12:00:41,  0.18it/s, v_num=0, loss/train=4.510]Epoch 0:   0%|          | 6/7584 [00:34<12:02:41,  0.17it/s, v_num=0, loss/train=4.550]Epoch 0:   0%|          | 7/7584 [00:49<14:53:46,  0.14it/s, v_num=0, loss/train=4.550]Epoch 0:   0%|          | 7/7584 [00:49<14:55:51,  0.14it/s, v_num=0, loss/train=4.560]Epoch 0:   0%|          | 8/7584 [00:53<13:57:10,  0.15it/s, v_num=0, loss/train=4.560]Epoch 0:   0%|          | 8/7584 [00:53<13:59:14,  0.15it/s, v_num=0, loss/train=4.150]Epoch 0:   0%|          | 9/7584 [00:56<13:08:42,  0.16it/s, v_num=0, loss/train=4.150]Epoch 0:   0%|          | 9/7584 [00:56<13:10:05,  0.16it/s, v_num=0, loss/train=4.010]Epoch 0:   0%|          | 10/7584 [00:59<12:33:53,  0.17it/s, v_num=0, loss/train=4.010]Epoch 0:   0%|          | 10/7584 [00:59<12:35:10,  0.17it/s, v_num=0, loss/train=4.090]Epoch 0:   0%|          | 11/7584 [01:03<12:10:40,  0.17it/s, v_num=0, loss/train=4.090]Epoch 0:   0%|          | 11/7584 [01:03<12:12:27,  0.17it/s, v_num=0, loss/train=4.220]Epoch 0:   0%|          | 12/7584 [01:16<13:24:52,  0.16it/s, v_num=0, loss/train=4.220]Epoch 0:   0%|          | 12/7584 [01:16<13:25:54,  0.16it/s, v_num=0, loss/train=4.170]Epoch 0:   0%|          | 13/7584 [01:20<13:02:53,  0.16it/s, v_num=0, loss/train=4.170]Epoch 0:   0%|          | 13/7584 [01:20<13:04:00,  0.16it/s, v_num=0, loss/train=3.900]Epoch 0:   0%|          | 14/7584 [01:24<12:39:13,  0.17it/s, v_num=0, loss/train=3.900]Epoch 0:   0%|          | 14/7584 [01:24<12:40:21,  0.17it/s, v_num=0, loss/train=4.030]Epoch 0:   0%|          | 15/7584 [01:27<12:18:59,  0.17it/s, v_num=0, loss/train=4.030]Epoch 0:   0%|          | 15/7584 [01:27<12:19:48,  0.17it/s, v_num=0, loss/train=3.910]Epoch 0:   0%|          | 16/7584 [01:32<12:09:36,  0.17it/s, v_num=0, loss/train=3.910]Epoch 0:   0%|          | 16/7584 [01:32<12:11:10,  0.17it/s, v_num=0, loss/train=4.010]Epoch 0:   0%|          | 17/7584 [01:44<12:55:52,  0.16it/s, v_num=0, loss/train=4.010]Epoch 0:   0%|          | 17/7584 [01:44<12:56:44,  0.16it/s, v_num=0, loss/train=3.890]Epoch 0:   0%|          | 18/7584 [01:51<13:02:21,  0.16it/s, v_num=0, loss/train=3.890]Epoch 0:   0%|          | 18/7584 [01:51<13:03:01,  0.16it/s, v_num=0, loss/train=3.710]Epoch 0:   0%|          | 19/7584 [01:55<12:44:41,  0.16it/s, v_num=0, loss/train=3.710]Epoch 0:   0%|          | 19/7584 [01:55<12:45:30,  0.16it/s, v_num=0, loss/train=3.900]Epoch 0:   0%|          | 20/7584 [01:59<12:32:15,  0.17it/s, v_num=0, loss/train=3.900]Epoch 0:   0%|          | 20/7584 [01:59<12:32:58,  0.17it/s, v_num=0, loss/train=3.800]Epoch 0:   0%|          | 21/7584 [02:04<12:25:18,  0.17it/s, v_num=0, loss/train=3.800]Epoch 0:   0%|          | 21/7584 [02:04<12:25:52,  0.17it/s, v_num=0, loss/train=3.760]Epoch 0:   0%|          | 22/7584 [02:20<13:26:05,  0.16it/s, v_num=0, loss/train=3.760]Epoch 0:   0%|          | 22/7584 [02:20<13:26:40,  0.16it/s, v_num=0, loss/train=3.840]Epoch 0:   0%|          | 23/7584 [02:24<13:11:46,  0.16it/s, v_num=0, loss/train=3.840]Epoch 0:   0%|          | 23/7584 [02:24<13:12:21,  0.16it/s, v_num=0, loss/train=3.850]Epoch 0:   0%|          | 24/7584 [02:28<12:57:57,  0.16it/s, v_num=0, loss/train=3.850]Epoch 0:   0%|          | 24/7584 [02:28<12:58:41,  0.16it/s, v_num=0, loss/train=3.920]Epoch 0:   0%|          | 25/7584 [02:32<12:46:42,  0.16it/s, v_num=0, loss/train=3.920]Epoch 0:   0%|          | 25/7584 [02:32<12:47:30,  0.16it/s, v_num=0, loss/train=3.810]Epoch 0:   0%|          | 26/7584 [02:44<13:18:23,  0.16it/s, v_num=0, loss/train=3.810]Epoch 0:   0%|          | 26/7584 [02:44<13:18:53,  0.16it/s, v_num=0, loss/train=3.760]Epoch 0:   0%|          | 27/7584 [02:52<13:23:22,  0.16it/s, v_num=0, loss/train=3.760]Epoch 0:   0%|          | 27/7584 [02:52<13:23:51,  0.16it/s, v_num=0, loss/train=3.840]Epoch 0:   0%|          | 28/7584 [02:56<13:12:18,  0.16it/s, v_num=0, loss/train=3.840]Epoch 0:   0%|          | 28/7584 [02:56<13:12:53,  0.16it/s, v_num=0, loss/train=3.760]Epoch 0:   0%|          | 29/7584 [03:02<13:10:23,  0.16it/s, v_num=0, loss/train=3.760]Epoch 0:   0%|          | 29/7584 [03:02<13:10:44,  0.16it/s, v_num=0, loss/train=3.600]Epoch 0:   0%|          | 30/7584 [03:05<12:59:10,  0.16it/s, v_num=0, loss/train=3.600]Epoch 0:   0%|          | 30/7584 [03:05<12:59:39,  0.16it/s, v_num=0, loss/train=4.020]Epoch 0:   0%|          | 31/7584 [03:19<13:29:13,  0.16it/s, v_num=0, loss/train=4.020]Epoch 0:   0%|          | 31/7584 [03:19<13:29:38,  0.16it/s, v_num=0, loss/train=3.540]Epoch 0:   0%|          | 32/7584 [03:23<13:21:36,  0.16it/s, v_num=0, loss/train=3.540]Epoch 0:   0%|          | 32/7584 [03:23<13:22:00,  0.16it/s, v_num=0, loss/train=3.520]Epoch 0:   0%|          | 33/7584 [03:27<13:09:34,  0.16it/s, v_num=0, loss/train=3.520]Epoch 0:   0%|          | 33/7584 [03:27<13:09:56,  0.16it/s, v_num=0, loss/train=3.310]Epoch 0:   0%|          | 34/7584 [03:30<13:00:17,  0.16it/s, v_num=0, loss/train=3.310]Epoch 0:   0%|          | 34/7584 [03:31<13:00:56,  0.16it/s, v_num=0, loss/train=3.250]Epoch 0:   0%|          | 35/7584 [03:34<12:50:13,  0.16it/s, v_num=0, loss/train=3.250]Epoch 0:   0%|          | 35/7584 [03:34<12:50:35,  0.16it/s, v_num=0, loss/train=3.070]Epoch 0:   0%|          | 36/7584 [03:48<13:19:30,  0.16it/s, v_num=0, loss/train=3.070]Epoch 0:   0%|          | 36/7584 [03:48<13:19:52,  0.16it/s, v_num=0, loss/train=3.300]Epoch 0:   0%|          | 37/7584 [03:52<13:08:42,  0.16it/s, v_num=0, loss/train=3.300]Epoch 0:   0%|          | 37/7584 [03:52<13:09:03,  0.16it/s, v_num=0, loss/train=3.470]Epoch 0:   1%|          | 38/7584 [03:55<12:59:50,  0.16it/s, v_num=0, loss/train=3.470]Epoch 0:   1%|          | 38/7584 [03:55<13:00:12,  0.16it/s, v_num=0, loss/train=3.070]Epoch 0:   1%|          | 39/7584 [04:00<12:56:00,  0.16it/s, v_num=0, loss/train=3.070]Epoch 0:   1%|          | 39/7584 [04:00<12:56:22,  0.16it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 40/7584 [04:03<12:46:37,  0.16it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 40/7584 [04:04<12:47:00,  0.16it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 41/7584 [04:18<13:12:05,  0.16it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 41/7584 [04:18<13:12:22,  0.16it/s, v_num=0, loss/train=3.300]Epoch 0:   1%|          | 42/7584 [04:23<13:08:37,  0.16it/s, v_num=0, loss/train=3.300]Epoch 0:   1%|          | 42/7584 [04:23<13:08:59,  0.16it/s, v_num=0, loss/train=3.140]Epoch 0:   1%|          | 43/7584 [04:26<12:59:52,  0.16it/s, v_num=0, loss/train=3.140]Epoch 0:   1%|          | 43/7584 [04:26<13:00:13,  0.16it/s, v_num=0, loss/train=3.150]Epoch 0:   1%|          | 44/7584 [04:30<12:51:48,  0.16it/s, v_num=0, loss/train=3.150]Epoch 0:   1%|          | 44/7584 [04:30<12:52:09,  0.16it/s, v_num=0, loss/train=3.280]Epoch 0:   1%|          | 45/7584 [04:33<12:43:55,  0.16it/s, v_num=0, loss/train=3.280]Epoch 0:   1%|          | 45/7584 [04:33<12:44:17,  0.16it/s, v_num=0, loss/train=3.070]Epoch 0:   1%|          | 46/7584 [04:48<13:07:00,  0.16it/s, v_num=0, loss/train=3.070]Epoch 0:   1%|          | 46/7584 [04:48<13:07:24,  0.16it/s, v_num=0, loss/train=3.120]Epoch 0:   1%|          | 47/7584 [04:51<13:00:21,  0.16it/s, v_num=0, loss/train=3.120]Epoch 0:   1%|          | 47/7584 [04:52<13:00:39,  0.16it/s, v_num=0, loss/train=3.090]Epoch 0:   1%|          | 48/7584 [04:54<12:51:48,  0.16it/s, v_num=0, loss/train=3.090]Epoch 0:   1%|          | 48/7584 [04:55<12:52:03,  0.16it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|          | 49/7584 [04:58<12:44:04,  0.16it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|          | 49/7584 [04:58<12:44:24,  0.16it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 50/7584 [05:02<12:40:20,  0.17it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 50/7584 [05:02<12:40:37,  0.17it/s, v_num=0, loss/train=3.090]Epoch 0:   1%|          | 51/7584 [05:06<12:33:56,  0.17it/s, v_num=0, loss/train=3.090]Epoch 0:   1%|          | 51/7584 [05:06<12:34:16,  0.17it/s, v_num=0, loss/train=2.890]Epoch 0:   1%|          | 52/7584 [05:18<12:49:03,  0.16it/s, v_num=0, loss/train=2.890]Epoch 0:   1%|          | 52/7584 [05:18<12:49:21,  0.16it/s, v_num=0, loss/train=3.140]Epoch 0:   1%|          | 53/7584 [05:21<12:42:25,  0.16it/s, v_num=0, loss/train=3.140]Epoch 0:   1%|          | 53/7584 [05:22<12:42:39,  0.16it/s, v_num=0, loss/train=3.070]Epoch 0:   1%|          | 54/7584 [05:25<12:35:53,  0.17it/s, v_num=0, loss/train=3.070]Epoch 0:   1%|          | 54/7584 [05:25<12:36:12,  0.17it/s, v_num=0, loss/train=3.450]Epoch 0:   1%|          | 55/7584 [05:28<12:30:01,  0.17it/s, v_num=0, loss/train=3.450]Epoch 0:   1%|          | 55/7584 [05:28<12:30:23,  0.17it/s, v_num=0, loss/train=3.050]Epoch 0:   1%|          | 56/7584 [05:35<12:32:40,  0.17it/s, v_num=0, loss/train=3.050]Epoch 0:   1%|          | 56/7584 [05:36<12:32:51,  0.17it/s, v_num=0, loss/train=3.030]Epoch 0:   1%|          | 57/7584 [05:47<12:44:10,  0.16it/s, v_num=0, loss/train=3.030]Epoch 0:   1%|          | 57/7584 [05:47<12:44:32,  0.16it/s, v_num=0, loss/train=3.340]Epoch 0:   1%|          | 58/7584 [05:51<12:40:00,  0.17it/s, v_num=0, loss/train=3.340]Epoch 0:   1%|          | 58/7584 [05:51<12:40:16,  0.16it/s, v_num=0, loss/train=3.160]Epoch 0:   1%|          | 59/7584 [05:55<12:35:16,  0.17it/s, v_num=0, loss/train=3.160]Epoch 0:   1%|          | 59/7584 [05:55<12:35:34,  0.17it/s, v_num=0, loss/train=3.480]Epoch 0:   1%|          | 60/7584 [05:58<12:29:32,  0.17it/s, v_num=0, loss/train=3.480]Epoch 0:   1%|          | 60/7584 [05:58<12:29:45,  0.17it/s, v_num=0, loss/train=3.130]Epoch 0:   1%|          | 61/7584 [06:02<12:25:37,  0.17it/s, v_num=0, loss/train=3.130]Epoch 0:   1%|          | 61/7584 [06:02<12:25:49,  0.17it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|          | 62/7584 [06:17<12:43:53,  0.16it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|          | 62/7584 [06:17<12:44:17,  0.16it/s, v_num=0, loss/train=3.160]Epoch 0:   1%|          | 63/7584 [06:21<12:38:52,  0.17it/s, v_num=0, loss/train=3.160]Epoch 0:   1%|          | 63/7584 [06:21<12:39:05,  0.17it/s, v_num=0, loss/train=3.010]Epoch 0:   1%|          | 64/7584 [06:24<12:33:46,  0.17it/s, v_num=0, loss/train=3.010]Epoch 0:   1%|          | 64/7584 [06:25<12:34:00,  0.17it/s, v_num=0, loss/train=3.400]Epoch 0:   1%|          | 65/7584 [06:28<12:28:13,  0.17it/s, v_num=0, loss/train=3.400]Epoch 0:   1%|          | 65/7584 [06:28<12:28:25,  0.17it/s, v_num=0, loss/train=3.020]Epoch 0:   1%|          | 66/7584 [06:31<12:23:24,  0.17it/s, v_num=0, loss/train=3.020]Epoch 0:   1%|          | 66/7584 [06:31<12:23:36,  0.17it/s, v_num=0, loss/train=2.920]Epoch 0:   1%|          | 67/7584 [06:46<12:39:38,  0.16it/s, v_num=0, loss/train=2.920]Epoch 0:   1%|          | 67/7584 [06:46<12:39:51,  0.16it/s, v_num=0, loss/train=3.330]Epoch 0:   1%|          | 68/7584 [06:49<12:35:11,  0.17it/s, v_num=0, loss/train=3.330]Epoch 0:   1%|          | 68/7584 [06:50<12:35:25,  0.17it/s, v_num=0, loss/train=2.990]Epoch 0:   1%|          | 69/7584 [06:53<12:30:39,  0.17it/s, v_num=0, loss/train=2.990]Epoch 0:   1%|          | 69/7584 [06:53<12:30:53,  0.17it/s, v_num=0, loss/train=3.330]Epoch 0:   1%|          | 70/7584 [06:56<12:25:35,  0.17it/s, v_num=0, loss/train=3.330]Epoch 0:   1%|          | 70/7584 [06:56<12:25:50,  0.17it/s, v_num=0, loss/train=3.090]Epoch 0:   1%|          | 71/7584 [07:00<12:20:53,  0.17it/s, v_num=0, loss/train=3.090]Epoch 0:   1%|          | 71/7584 [07:00<12:21:04,  0.17it/s, v_num=0, loss/train=3.240]Epoch 0:   1%|          | 72/7584 [07:05<12:20:27,  0.17it/s, v_num=0, loss/train=3.240]Epoch 0:   1%|          | 72/7584 [07:05<12:20:39,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|          | 73/7584 [07:18<12:32:45,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|          | 73/7584 [07:19<12:32:56,  0.17it/s, v_num=0, loss/train=3.290]Epoch 0:   1%|          | 74/7584 [07:22<12:28:51,  0.17it/s, v_num=0, loss/train=3.290]Epoch 0:   1%|          | 74/7584 [07:22<12:28:59,  0.17it/s, v_num=0, loss/train=3.290]Epoch 0:   1%|          | 75/7584 [07:26<12:24:37,  0.17it/s, v_num=0, loss/train=3.290]Epoch 0:   1%|          | 75/7584 [07:26<12:24:46,  0.17it/s, v_num=0, loss/train=3.470]Epoch 0:   1%|          | 76/7584 [07:29<12:20:15,  0.17it/s, v_num=0, loss/train=3.470]Epoch 0:   1%|          | 76/7584 [07:29<12:20:26,  0.17it/s, v_num=0, loss/train=3.080]Epoch 0:   1%|          | 77/7584 [07:35<12:20:06,  0.17it/s, v_num=0, loss/train=3.080]Epoch 0:   1%|          | 77/7584 [07:35<12:20:15,  0.17it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 78/7584 [07:48<12:30:41,  0.17it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 78/7584 [07:48<12:30:57,  0.17it/s, v_num=0, loss/train=3.390]Epoch 0:   1%|          | 79/7584 [07:52<12:27:55,  0.17it/s, v_num=0, loss/train=3.390]Epoch 0:   1%|          | 79/7584 [07:52<12:28:06,  0.17it/s, v_num=0, loss/train=3.420]Epoch 0:   1%|          | 80/7584 [07:56<12:24:27,  0.17it/s, v_num=0, loss/train=3.420]Epoch 0:   1%|          | 80/7584 [07:56<12:24:37,  0.17it/s, v_num=0, loss/train=3.480]Epoch 0:   1%|          | 81/7584 [07:59<12:20:41,  0.17it/s, v_num=0, loss/train=3.480]Epoch 0:   1%|          | 81/7584 [07:59<12:20:52,  0.17it/s, v_num=0, loss/train=3.440]Epoch 0:   1%|          | 82/7584 [08:10<12:28:16,  0.17it/s, v_num=0, loss/train=3.440]Epoch 0:   1%|          | 82/7584 [08:10<12:28:25,  0.17it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 83/7584 [08:18<12:31:26,  0.17it/s, v_num=0, loss/train=2.970]Epoch 0:   1%|          | 83/7584 [08:18<12:31:34,  0.17it/s, v_num=0, loss/train=2.980]Epoch 0:   1%|          | 84/7584 [08:22<12:27:35,  0.17it/s, v_num=0, loss/train=2.980]Epoch 0:   1%|          | 84/7584 [08:22<12:27:45,  0.17it/s, v_num=0, loss/train=3.050]Epoch 0:   1%|          | 85/7584 [08:25<12:23:27,  0.17it/s, v_num=0, loss/train=3.050]Epoch 0:   1%|          | 85/7584 [08:25<12:23:35,  0.17it/s, v_num=0, loss/train=3.150]Epoch 0:   1%|          | 86/7584 [08:28<12:18:54,  0.17it/s, v_num=0, loss/train=3.150]Epoch 0:   1%|          | 86/7584 [08:28<12:19:02,  0.17it/s, v_num=0, loss/train=3.010]Epoch 0:   1%|          | 87/7584 [08:32<12:15:22,  0.17it/s, v_num=0, loss/train=3.010]Epoch 0:   1%|          | 87/7584 [08:32<12:15:30,  0.17it/s, v_num=0, loss/train=3.510]Epoch 0:   1%|          | 88/7584 [08:42<12:21:34,  0.17it/s, v_num=0, loss/train=3.510]Epoch 0:   1%|          | 88/7584 [08:42<12:21:42,  0.17it/s, v_num=0, loss/train=3.100]Epoch 0:   1%|          | 89/7584 [08:47<12:20:58,  0.17it/s, v_num=0, loss/train=3.100]Epoch 0:   1%|          | 89/7584 [08:48<12:21:06,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 90/7584 [08:52<12:18:18,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 90/7584 [08:52<12:18:31,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 91/7584 [08:56<12:15:44,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 91/7584 [08:56<12:15:55,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 92/7584 [08:59<12:11:55,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   1%|          | 92/7584 [08:59<12:12:04,  0.17it/s, v_num=0, loss/train=3.360]Epoch 0:   1%|          | 93/7584 [09:02<12:08:36,  0.17it/s, v_num=0, loss/train=3.360]Epoch 0:   1%|          | 93/7584 [09:02<12:08:44,  0.17it/s, v_num=0, loss/train=3.370]Epoch 0:   1%|          | 94/7584 [09:16<12:19:41,  0.17it/s, v_num=0, loss/train=3.370]Epoch 0:   1%|          | 94/7584 [09:17<12:19:50,  0.17it/s, v_num=0, loss/train=3.560]Epoch 0:   1%|▏         | 95/7584 [09:21<12:18:18,  0.17it/s, v_num=0, loss/train=3.560]Epoch 0:   1%|▏         | 95/7584 [09:22<12:18:26,  0.17it/s, v_num=0, loss/train=2.820]Epoch 0:   1%|▏         | 96/7584 [09:25<12:15:01,  0.17it/s, v_num=0, loss/train=2.820]Epoch 0:   1%|▏         | 96/7584 [09:25<12:15:16,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|▏         | 97/7584 [09:28<12:11:23,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|▏         | 97/7584 [09:28<12:11:31,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|▏         | 98/7584 [09:32<12:08:44,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|▏         | 98/7584 [09:32<12:08:55,  0.17it/s, v_num=0, loss/train=2.740]Epoch 0:   1%|▏         | 99/7584 [09:47<12:20:53,  0.17it/s, v_num=0, loss/train=2.740]Epoch 0:   1%|▏         | 99/7584 [09:48<12:21:01,  0.17it/s, v_num=0, loss/train=3.080]Epoch 0:   1%|▏         | 100/7584 [09:52<12:18:33,  0.17it/s, v_num=0, loss/train=3.080]Epoch 0:   1%|▏         | 100/7584 [09:52<12:18:44,  0.17it/s, v_num=0, loss/train=3.030]Epoch 0:   1%|▏         | 101/7584 [09:55<12:15:40,  0.17it/s, v_num=0, loss/train=3.030]Epoch 0:   1%|▏         | 101/7584 [09:55<12:15:49,  0.17it/s, v_num=0, loss/train=2.840]Epoch 0:   1%|▏         | 102/7584 [09:59<12:13:00,  0.17it/s, v_num=0, loss/train=2.840]Epoch 0:   1%|▏         | 102/7584 [09:59<12:13:07,  0.17it/s, v_num=0, loss/train=2.840]Epoch 0:   1%|▏         | 103/7584 [10:06<12:14:06,  0.17it/s, v_num=0, loss/train=2.840]Epoch 0:   1%|▏         | 103/7584 [10:06<12:14:13,  0.17it/s, v_num=0, loss/train=3.360]Epoch 0:   1%|▏         | 104/7584 [10:19<12:22:16,  0.17it/s, v_num=0, loss/train=3.360]Epoch 0:   1%|▏         | 104/7584 [10:19<12:22:27,  0.17it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|▏         | 105/7584 [10:23<12:20:15,  0.17it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|▏         | 105/7584 [10:23<12:20:23,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|▏         | 106/7584 [10:27<12:17:32,  0.17it/s, v_num=0, loss/train=3.220]Epoch 0:   1%|▏         | 106/7584 [10:27<12:17:41,  0.17it/s, v_num=0, loss/train=3.020]Epoch 0:   1%|▏         | 107/7584 [10:30<12:14:42,  0.17it/s, v_num=0, loss/train=3.020]Epoch 0:   1%|▏         | 107/7584 [10:30<12:14:49,  0.17it/s, v_num=0, loss/train=2.950]Epoch 0:   1%|▏         | 108/7584 [10:46<12:25:28,  0.17it/s, v_num=0, loss/train=2.950]Epoch 0:   1%|▏         | 108/7584 [10:46<12:25:35,  0.17it/s, v_num=0, loss/train=2.820]Epoch 0:   1%|▏         | 109/7584 [10:50<12:23:11,  0.17it/s, v_num=0, loss/train=2.820]Epoch 0:   1%|▏         | 109/7584 [10:50<12:23:18,  0.17it/s, v_num=0, loss/train=3.280]Epoch 0:   1%|▏         | 110/7584 [10:53<12:20:35,  0.17it/s, v_num=0, loss/train=3.280]Epoch 0:   1%|▏         | 110/7584 [10:54<12:20:46,  0.17it/s, v_num=0, loss/train=2.910]Epoch 0:   1%|▏         | 111/7584 [10:58<12:18:27,  0.17it/s, v_num=0, loss/train=2.910]Epoch 0:   1%|▏         | 111/7584 [10:58<12:18:37,  0.17it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|▏         | 112/7584 [11:02<12:16:23,  0.17it/s, v_num=0, loss/train=3.200]Epoch 0:   1%|▏         | 112/7584 [11:02<12:16:30,  0.17it/s, v_num=0, loss/train=2.900]Epoch 0:   1%|▏         | 113/7584 [11:20<12:29:57,  0.17it/s, v_num=0, loss/train=2.900]Epoch 0:   1%|▏         | 113/7584 [11:20<12:30:06,  0.17it/s, v_num=0, loss/train=2.860]Epoch 0:   2%|▏         | 114/7584 [11:25<12:28:10,  0.17it/s, v_num=0, loss/train=2.860]Epoch 0:   2%|▏         | 114/7584 [11:25<12:28:19,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   2%|▏         | 115/7584 [11:28<12:25:46,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   2%|▏         | 115/7584 [11:29<12:25:55,  0.17it/s, v_num=0, loss/train=3.020]Epoch 0:   2%|▏         | 116/7584 [11:32<12:22:35,  0.17it/s, v_num=0, loss/train=3.020]Epoch 0:   2%|▏         | 116/7584 [11:32<12:22:43,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   2%|▏         | 117/7584 [11:42<12:27:19,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   2%|▏         | 117/7584 [11:42<12:27:27,  0.17it/s, v_num=0, loss/train=3.080]Epoch 0:   2%|▏         | 118/7584 [11:50<12:28:56,  0.17it/s, v_num=0, loss/train=3.080]Epoch 0:   2%|▏         | 118/7584 [11:50<12:29:03,  0.17it/s, v_num=0, loss/train=3.520]Epoch 0:   2%|▏         | 119/7584 [11:53<12:26:24,  0.17it/s, v_num=0, loss/train=3.520]Epoch 0:   2%|▏         | 119/7584 [11:54<12:26:34,  0.17it/s, v_num=0, loss/train=3.230]Epoch 0:   2%|▏         | 120/7584 [11:58<12:24:45,  0.17it/s, v_num=0, loss/train=3.230]Epoch 0:   2%|▏         | 120/7584 [11:58<12:24:53,  0.17it/s, v_num=0, loss/train=3.400]Epoch 0:   2%|▏         | 121/7584 [12:07<12:27:58,  0.17it/s, v_num=0, loss/train=3.400]Epoch 0:   2%|▏         | 121/7584 [12:07<12:28:03,  0.17it/s, v_num=0, loss/train=3.130]Epoch 0:   2%|▏         | 122/7584 [12:12<12:26:59,  0.17it/s, v_num=0, loss/train=3.130]Epoch 0:   2%|▏         | 122/7584 [12:12<12:27:05,  0.17it/s, v_num=0, loss/train=3.070]Epoch 0:   2%|▏         | 123/7584 [12:16<12:24:38,  0.17it/s, v_num=0, loss/train=3.070]Epoch 0:   2%|▏         | 123/7584 [12:16<12:24:45,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   2%|▏         | 124/7584 [12:23<12:25:41,  0.17it/s, v_num=0, loss/train=3.210]Epoch 0:   2%|▏         | 124/7584 [12:23<12:25:49,  0.17it/s, v_num=0, loss/train=3.290]Epoch 0:   2%|▏         | 125/7584 [12:27<12:23:23,  0.17it/s, v_num=0, loss/train=3.290]Epoch 0:   2%|▏         | 125/7584 [12:27<12:23:31,  0.17it/s, v_num=0, loss/train=3.340]Epoch 0:   2%|▏         | 126/7584 [12:37<12:27:00,  0.17it/s, v_num=0, loss/train=3.340]Epoch 0:   2%|▏         | 126/7584 [12:37<12:27:07,  0.17it/s, v_num=0, loss/train=2.940]Epoch 0:   2%|▏         | 127/7584 [12:41<12:24:48,  0.17it/s, v_num=0, loss/train=2.940]Epoch 0:   2%|▏         | 127/7584 [12:41<12:24:56,  0.17it/s, v_num=0, loss/train=2.940]Epoch 0:   2%|▏         | 128/7584 [12:46<12:24:10,  0.17it/s, v_num=0, loss/train=2.940]Epoch 0:   2%|▏         | 128/7584 [12:46<12:24:15,  0.17it/s, v_num=0, loss/train=3.520]Epoch 0:   2%|▏         | 129/7584 [12:50<12:21:51,  0.17it/s, v_num=0, loss/train=3.520]Epoch 0:   2%|▏         | 129/7584 [12:50<12:21:57,  0.17it/s, v_num=0, loss/train=3.060]Epoch 0:   2%|▏         | 130/7584 [12:55<12:20:51,  0.17it/s, v_num=0, loss/train=3.060]Epoch 0:   2%|▏         | 130/7584 [12:55<12:21:00,  0.17it/s, v_num=0, loss/train=3.130]Epoch 0:   2%|▏         | 131/7584 [13:01<12:20:33,  0.17it/s, v_num=0, loss/train=3.130]Epoch 0:   2%|▏         | 131/7584 [13:01<12:20:39,  0.17it/s, v_num=0, loss/train=3.160]Epoch 0:   2%|▏         | 132/7584 [13:05<12:18:39,  0.17it/s, v_num=0, loss/train=3.160]Epoch 0:   2%|▏         | 132/7584 [13:05<12:18:45,  0.17it/s, v_num=0, loss/train=3.350][rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15
Epoch 0:   2%|▏         | 133/7584 [13:08<12:16:17,  0.17it/s, v_num=0, loss/train=3.350]Epoch 0:   2%|▏         | 133/7584 [13:08<12:16:23,  0.17it/s, v_num=0, loss/train=3.200]Epoch 0:   2%|▏         | 133/7584 [13:09<12:16:46,  0.17it/s, v_num=0, loss/train=3.200]